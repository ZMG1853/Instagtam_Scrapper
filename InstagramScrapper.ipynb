{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#requests\n",
    "import requests\n",
    "import urllib\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "#data, strucuture and maths\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import string\n",
    "from  more_itertools import unique_everseen\n",
    "import random\n",
    "\n",
    "#progress,performance and management\n",
    "from tqdm import tqdm_notebook\n",
    "import threading\n",
    "import os\n",
    "import ssl\n",
    "from IPython.display import clear_output\n",
    "import platform\n",
    "import os\n",
    "\n",
    "# imports used in Selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#time\n",
    "from time import sleep\n",
    "import time\n",
    "\n",
    "#text processing / regex\n",
    "import regex\n",
    "import re\n",
    "\n",
    "#make wide\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#passwords\n",
    "import getpass\n",
    "\n",
    "\n",
    "\n",
    "class InstagramScraper():\n",
    "\n",
    "    \"\"\"\n",
    "    Class that allows you to scrape the content of Instagram posts, either\n",
    "    a profile or a hashtag.\n",
    "\n",
    "    Initialised with the location of your Chromedriver location\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,driver_loc='/Users/sam/Desktop/Chromedriver/chromedriver'):\n",
    "\n",
    "        self.driver_loc = driver_loc\n",
    "\n",
    "    def multithreadCompile(self,thread_count,iteration_list,func):\n",
    "\n",
    "        \"\"\"\n",
    "        This function compiles the batched needed for mult-threadding\n",
    "\n",
    "        Args:\n",
    "\n",
    "            thread_count is the number of threads used for multi-threadding\n",
    "\n",
    "            iteration_list is the source list of urls to iterate over\n",
    "\n",
    "            func is the function to be used in the multi-thredding process\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            The batches that have been allocated to be run using the specified\n",
    "            function\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        jobs = [] #empty list for jobs\n",
    "\n",
    "        #distribute iteration list to batches and append to jobs list\n",
    "        batches = [i.tolist() for i in np.array_split(iteration_list,thread_count)]\n",
    "\n",
    "        for i in range(len(batches)):\n",
    "\n",
    "            jobs.append(threading.Thread(target=func,args=[batches[i]]))\n",
    "\n",
    "        return jobs\n",
    "\n",
    "    def multithreadExecute(self,jobs):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        This function executes the multi-threadding process\n",
    "\n",
    "        Args:\n",
    "\n",
    "            The batches that have been appended to a jobs list\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            Nothing, merely executes the multi-threadding\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Start the threads\n",
    "        for j in jobs:\n",
    "            print('execute working')\n",
    "            j.start()\n",
    "\n",
    "        # Ensure all of the threads have finished\n",
    "        for j in jobs:\n",
    "\n",
    "            j.join()\n",
    "\n",
    "        return\n",
    "\n",
    "    def getJson(self,url):\n",
    "\n",
    "        \"\"\"\n",
    "        This function exracts a JSON style dictionary from the html for any\n",
    "        given unique Instagram post\n",
    "\n",
    "        Args:\n",
    "\n",
    "            An Instagram post URL\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            JSON dictionary ouput\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        page = urlopen(url).read() #read url\n",
    "\n",
    "        data=BeautifulSoup(page, 'html.parser') #get a BeautifulSoup object\n",
    "\n",
    "        body = data.find('body') #find body element\n",
    "\n",
    "        script = body.find('script') #find script element\n",
    "\n",
    "        #some string formatting\n",
    "        raw = script.text.strip().replace('window._sharedData =', '').replace(';', '')\n",
    "\n",
    "        #load string\n",
    "        json_data=json.loads(raw)\n",
    "\n",
    "        return json_data #return JSON dictonary\n",
    "\n",
    "    def userDetails(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Functions that capture log in details and logs user into Instagram\n",
    "\n",
    "        Args:\n",
    "\n",
    "            None needed\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            Nothing\n",
    "\n",
    "        \"\"\"\n",
    "        #capture username\n",
    "        username = input('Enter username...')\n",
    "\n",
    "        #capture password\n",
    "        password = getpass.getpass('Enter password...')\n",
    "\n",
    "        self._password = password #retain password as attribute\n",
    "\n",
    "        self._username = username #retain user name as attribute\n",
    "\n",
    "        return\n",
    "\n",
    "    def openWebdriver(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Launches Chrome webdriver\n",
    "\n",
    "        Args:\n",
    "\n",
    "            None needed\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            driver\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        #intiate driver\n",
    "        print(\"Launching driver...\")\n",
    "\n",
    "        #retain current driver as attribute\n",
    "        driver = webdriver.Chrome(self.driver_loc)\n",
    "\n",
    "        return driver\n",
    "\n",
    "    def closeWebdriver(self,driver):\n",
    "\n",
    "        \"\"\"\n",
    "        Closes Chrome webdriver\n",
    "\n",
    "        Args:\n",
    "\n",
    "            webDriver\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            Nothing\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        driver.close()\n",
    "\n",
    "        return\n",
    "\n",
    "    def instagramLogin(self,driver):\n",
    "\n",
    "        \"\"\"\n",
    "        Logs in to Instagram\n",
    "\n",
    "        Args:\n",
    "\n",
    "            Current webdriver\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            Current webdriver - logged into Instagram\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        #base url\n",
    "        driver.get('https://www.instagram.com/accounts/login/?source=auth_switcher')\n",
    "\n",
    "        sleep(2) #wait\n",
    "\n",
    "        #log in\n",
    "        username_field = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/article/div/div[1]/div/form/div[2]/div/label/input')\n",
    "\n",
    "        username_field.click() #click on username button\n",
    "\n",
    "        #send username\n",
    "        username_field.send_keys(self._username)\n",
    "\n",
    "        #locate element to click\n",
    "        try:\n",
    "            password_field = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/article/div/div[1]/div/form/div[3]/div/label/input')\n",
    "\n",
    "        except:\n",
    "            password_field = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/article/div/div[1]/div/form/div[4]/div/label/input')\n",
    "\n",
    "        password_field.click()\n",
    "\n",
    "        password_field.send_keys(self._password)\n",
    "\n",
    "        sleep(2)\n",
    "\n",
    "        #find log in button\n",
    "        login_button = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/article/div/div[1]/div/form/div[4]')\n",
    "\n",
    "        login_button.click()\n",
    "\n",
    "        sleep(3)\n",
    "\n",
    "        #locate floating window to click and close\n",
    "        floating_window = driver.find_element_by_class_name('piCib')\n",
    "\n",
    "        button = floating_window.find_element_by_class_name('mt3GC')\n",
    "\n",
    "        not_now = button.find_element_by_xpath('/html/body/div[4]/div/div/div[3]/button[2]')\n",
    "\n",
    "        not_now.click()\n",
    "\n",
    "        return driver\n",
    "\n",
    "    def setTarget(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Function that sets either a profile or a hashtag as a target\n",
    "\n",
    "        Args:\n",
    "\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            base url to scrape - either a hashtag page or a profile page\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        #tou can choose either hashtag search or a profile to search\n",
    "        route = input('What do you want to scrape, profile posts or hashtags? (p/h)')\n",
    "\n",
    "        #if hashtags\n",
    "        if route == 'h':\n",
    "\n",
    "            #set hashtag\n",
    "            hashtag = input('Which hashtag do you want to scrape posts for: ')\n",
    "\n",
    "            self.target_label = '#'+hashtag #retain hashtag as attribute\n",
    "\n",
    "            tag_url = 'https://www.instagram.com/explore/tags/' #set base url\n",
    "\n",
    "            self._target = tag_url+hashtag #set url to scrape from\n",
    "\n",
    "            return self._target #return url to scrape from\n",
    "\n",
    "        else:\n",
    "\n",
    "            profile = input('What profile do you want to scrape posts for: ')\n",
    "\n",
    "            self.target_label = '@'+profile #retain profile as attribute\n",
    "\n",
    "            profile_url = 'https://www.instagram.com/' #set base url\n",
    "\n",
    "            self._target = profile_url+profile #set url to scrape from\n",
    "\n",
    "            return self._target #return url to scrape from\n",
    "\n",
    "    def scrapeLinks(self,url):\n",
    "\n",
    "        \"\"\"\n",
    "        Function that scrapes the links needed\n",
    "\n",
    "        Args:\n",
    "\n",
    "            target_url\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            Nothing - but retains a list of urls to scrape\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        #pass url as argument to Selenium webDriver, loads url\n",
    "        self.activedriver.get(url)\n",
    "\n",
    "        options = webdriver.ChromeOptions()\n",
    "\n",
    "        #start maximised\n",
    "        options.add_argument(\"--start-maximized\")\n",
    "\n",
    "        #gets scroll height\n",
    "        last_height = self.activedriver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        #initiate empty list for unique Instagram links\n",
    "        links = []\n",
    "\n",
    "        #some lines for user interactivity / selection of link target(n)\n",
    "        print(\"\\n\")\n",
    "        target = input(\"How many links do you want to scrape (minimum)?: \")\n",
    "        print(\"\\n\")\n",
    "        print(\"Staring Selenium scrape, please keep browser open.\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        #this loops round until n links achieved or page has ended\n",
    "\n",
    "        while True:\n",
    "\n",
    "            source = self.activedriver.page_source\n",
    "\n",
    "            data= BeautifulSoup(source, 'html.parser')\n",
    "\n",
    "            body = data.find('body')\n",
    "\n",
    "            #script = body.find('span')\n",
    "\n",
    "            for link in body.findAll('a'):\n",
    "\n",
    "                if re.match(\"/p\", link.get('href')):\n",
    "\n",
    "                    links.append('https://www.instagram.com'+link.get('href'))\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            # Scroll down to bottom\n",
    "            self.activedriver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            # Wait to load page\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = self.activedriver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "            #if no more content, scrape loop is terminated\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "\n",
    "            last_height = new_height\n",
    "\n",
    "            #update on successful links scraped\n",
    "            print(\"Scraped \", len(links),\" links, \", len(set(links)),' are unique')\n",
    "\n",
    "            #if n target met then while loop breaks\n",
    "            if len(set(links))>int(target):\n",
    "                break\n",
    "\n",
    "        #links are saved as an attribute for the class instance\n",
    "        self._links = list(unique_everseen(links))\n",
    "\n",
    "        #clear the screen and provide user feedback on performance\n",
    "        clear_output()\n",
    "\n",
    "        print(\"Finished scraping links. Maxed out at \", len(links),\" links, of which \", len(self._links),' are unique.')\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print(\"Unique links obtained. Closing driver\")\n",
    "\n",
    "        print(\"\\n\")\n",
    "        # close driver\n",
    "        self.closeWebdriver(self.activedriver)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def postDate(self,data):\n",
    "\n",
    "        \"\"\"\n",
    "        Function that gets the date of post\n",
    "        Args:\n",
    "            JSON dictionary for post\n",
    "        Returns:\n",
    "            datetime of post\n",
    "        \"\"\"\n",
    "\n",
    "        return datetime.utcfromtimestamp(data['entry_data']['PostPage'][0]['graphql']['shortcode_media']['taken_at_timestamp']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    def postUser(self,data):\n",
    "\n",
    "        \"\"\"\n",
    "        Function that gets the username of the person who posted\n",
    "        Args:\n",
    "            JSON dictionary for post\n",
    "        Returns:\n",
    "            username\n",
    "        \"\"\"\n",
    "        return data['entry_data']['PostPage'][0]['graphql']['shortcode_media']['owner']['username']\n",
    "\n",
    "    def postVerifiedUser(self,data):\n",
    "\n",
    "        \"\"\"\n",
    "        Function gets the verified status of the user\n",
    "        Args:\n",
    "            JSON dictionary for post\n",
    "        Returns:\n",
    "            verified status\n",
    "        \"\"\"\n",
    "        return data['entry_data']['PostPage'][0]['graphql']['shortcode_media']['owner']['is_verified']\n",
    "\n",
    "\n",
    "    def postLikes(self,data):\n",
    "\n",
    "        \"\"\"\n",
    "        Function that gets the number of likes the post received\n",
    "        Args:\n",
    "            JSON dictionary for post\n",
    "        Returns:\n",
    "            number of likes\n",
    "        \"\"\"\n",
    "\n",
    "        return data['entry_data']['PostPage'][0]['graphql']['shortcode_media']['edge_media_preview_like']['count']\n",
    "\n",
    "    def postVerifiedTags(self,data):\n",
    "\n",
    "        \"\"\"\n",
    "        Function that gets the verified tags that a post contains\n",
    "        Args:\n",
    "            JSON dictionary for post\n",
    "        Returns:\n",
    "            the verified tags in the post\n",
    "        \"\"\"\n",
    "\n",
    "        tag_end_point = data['entry_data']['PostPage'][0]['graphql']['shortcode_media']['edge_media_to_tagged_user']['edges']\n",
    "\n",
    "        entities = []\n",
    "\n",
    "        verif = []\n",
    "\n",
    "        for i in range(len(tag_end_point)):\n",
    "\n",
    "            entities.append(tag_end_point[i]['node']['user']['full_name'])\n",
    "\n",
    "            verif.append(tag_end_point[i]['node']['user']['is_verified'])\n",
    "\n",
    "        df = pd.DataFrame({'Brand':entities,'Verified':verif})\n",
    "\n",
    "        df = df[df.Verified == True]\n",
    "\n",
    "        if len(list(df.Brand)) < 1:\n",
    "\n",
    "            return np.nan\n",
    "\n",
    "        else:\n",
    "\n",
    "            return list(df.Brand)\n",
    "\n",
    "    def postUnverifiedTags(self,data):\n",
    "\n",
    "        \"\"\"\n",
    "        Function that gets the unverified tags a post contains\n",
    "        Args:\n",
    "            JSON dictionary for post\n",
    "        Returns:\n",
    "            the unverified tags in the post\n",
    "        \"\"\"\n",
    "\n",
    "        tag_end_point = data['entry_data']['PostPage'][0]['graphql']['shortcode_media']['edge_media_to_tagged_user']['edges']\n",
    "\n",
    "        tags = [] #emoty list for entities\n",
    "\n",
    "        verif = [] #empty list for verified status\n",
    "\n",
    "        #loop through\n",
    "        for i in range(len(tag_end_point)):\n",
    "\n",
    "            #append entities\n",
    "            tags.append(tag_end_point[i]['node']['user']['full_name'])\n",
    "\n",
    "            #append verified status\n",
    "            verif.append(tag_end_point[i]['node']['user']['is_verified'])\n",
    "\n",
    "        #DataFrame of verified / unverified tags\n",
    "        df = pd.DataFrame({'Tag':tags,'Verified':verif})\n",
    "\n",
    "        #subset on unverified tags\n",
    "        df = df[df.Verified == False]\n",
    "\n",
    "        #if there are unverified tags then return NaN else return unverified tags\n",
    "        if len(list(df.Tag)) < 1:\n",
    "\n",
    "            return np.nan\n",
    "\n",
    "        else:\n",
    "\n",
    "            return ''.join(list(df.Tag))\n",
    "\n",
    "    def postComment(self,data):\n",
    "\n",
    "        return data['entry_data']['PostPage'][0]['graphql']['shortcode_media']['edge_media_to_caption']['edges'][0]['node']['text']\n",
    "\n",
    "    #get location of post\n",
    "    def postLocation(self,data):\n",
    "\n",
    "        \"\"\"\n",
    "        Function that gets the post location if available\n",
    "        Args:\n",
    "            JSON dictionary for post\n",
    "        Returns:\n",
    "            the posts location\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "\n",
    "            if len(list(data['entry_data']['PostPage'][0]['graphql']['shortcode_media']['location']['name'])) > 0:\n",
    "\n",
    "                return data['entry_data']['PostPage'][0]['graphql']['shortcode_media']['location']['name']\n",
    "        except:\n",
    "\n",
    "            return np.nan\n",
    "\n",
    "    #get accessibility  / image data\n",
    "    def postAccessibility(self,data):\n",
    "        \n",
    "        \"\"\"\n",
    "        Function that gets the post accessibility data if available\n",
    "        Args:\n",
    "            JSON dictionary for post\n",
    "        Returns:\n",
    "            the accessibility data\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                image = data['entry_data']['PostPage'][0]['graphql']['shortcode_media']['accessibility_caption'].replace('Image may contain: ','').replace(' and ',', ').replace('one or more ','')\n",
    "\n",
    "                return image\n",
    "\n",
    "            except:\n",
    "                image = data['entry_data']['PostPage'][0]['graphql']['shortcode_media']['edge_sidecar_to_children']['edges'][0]['node']['accessibility_caption'].replace('Image may contain: ','').replace(' and ',', ').replace('one or more ','')\n",
    "\n",
    "                return image\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    #return original post link\n",
    "    def postLink(self,data):\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    The three main methods that combine all above\n",
    "    \"\"\"\n",
    "    #get user details, log in and initiate driver\n",
    "    def logIn(self):\n",
    "\n",
    "        self.userDetails()\n",
    "\n",
    "        driver = self.openWebdriver()\n",
    "\n",
    "        self.activedriver = self.instagramLogin(driver)\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "        print('Successfully logged in..ready to scrape')\n",
    "\n",
    "    #get all the unique links\n",
    "    def getLinks(self):\n",
    "\n",
    "        return self.scrapeLinks(self.setTarget())\n",
    "\n",
    "    #extract data and return dataframe\n",
    "    def getData(self):\n",
    "\n",
    "        #create empty lists for posts and comments\n",
    "        post_date_l = []\n",
    "\n",
    "        post_user_l = []\n",
    "\n",
    "        post_verif_l = []\n",
    "\n",
    "        post_likes_l = []\n",
    "\n",
    "        post_tags_v_l =[]\n",
    "\n",
    "        post_tags_u_l = []\n",
    "\n",
    "        post_l = []\n",
    "\n",
    "        post_location_l = []\n",
    "\n",
    "        post_insta_classifier_l = []\n",
    "\n",
    "        post_link_l = []\n",
    "\n",
    "        self._listStack = [post_date_l,post_user_l,post_verif_l,post_likes_l,post_tags_v_l,\n",
    "                      post_tags_u_l,post_l,post_location_l,post_insta_classifier_l,post_link_l]\n",
    "\n",
    "        self._functionStack = [ self.postDate,\n",
    "                                    self.postUser,\n",
    "                                    self.postVerifiedUser,\n",
    "                                    self.postLikes,\n",
    "                                    self.postVerifiedTags,\n",
    "                                    self.postUnverifiedTags,\n",
    "                                    self.postComment,\n",
    "                                    self.postLocation,\n",
    "                                    self.postAccessibility,\n",
    "                                    self.postLink]\n",
    "\n",
    "        def extractData(links=self._links):\n",
    "\n",
    "            #loops through and calls each data collection function on each link\n",
    "            for i in tqdm_notebook(range(len(links))):\n",
    "\n",
    "                try:\n",
    "\n",
    "                    data = self.getJson(links[i])\n",
    "\n",
    "                    for function in self._functionStack:\n",
    "\n",
    "                        if function != self._functionStack[-1]:\n",
    "\n",
    "                            try:\n",
    "\n",
    "                                self._listStack[self._functionStack.index(function)].append(function(data))\n",
    "\n",
    "                            except:\n",
    "\n",
    "                                 self._listStack[self._functionStack.index(function)].append(np.nan)\n",
    "                        else:\n",
    "                            self._listStack[-1].append(self._functionStack[-1](links[i]))\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "            return\n",
    "\n",
    "        # execute html parsing fuction using multi threading\n",
    "        print(\"Attemping multi-threading...\")\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        threads = int(input(\"How many threads?: \"))\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print(\"Executing...\")\n",
    "\n",
    "        self.multithreadExecute(self.multithreadCompile(threads,self._links,extractData))\n",
    "\n",
    "        #set up intial data structure\n",
    "        df = pd.DataFrame({'searched_for':[self.target_label]*len(post_l),\n",
    "                           'post_link' :post_link_l,\n",
    "                           'post_date':post_date_l,\n",
    "                           'post':post_l,\n",
    "                           'user':post_user_l,\n",
    "                           'user_verified_status': post_verif_l,\n",
    "                           'post_likes':post_likes_l,\n",
    "                           'post_verified_tags':post_tags_v_l,\n",
    "                           'post_unverified_tags':post_tags_u_l,\n",
    "                           'post_location':post_location_l,\n",
    "                           'post_image':post_insta_classifier_l,\n",
    "\n",
    "                               })\n",
    "\n",
    "        df.sort_values(by='post_date',ascending=False,inplace=True)\n",
    "\n",
    "        df.reset_index(drop=True,inplace=True) #reset index\n",
    "\n",
    "        self._df = df #retain final DataFrame as attribute\n",
    "        \n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "togetherness = InstagramScraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
